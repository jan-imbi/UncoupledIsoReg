% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{minimize_entropic_W}
\alias{minimize_entropic_W}
\title{Minimize the entropic Wasserstein distance}
\usage{
minimize_entropic_W(
  Y,
  A = NULL,
  AV = NULL,
  P_D = NULL,
  muStart = NULL,
  maxIter = 100L,
  minIter = 50L,
  sinkhornIter = 100L,
  eps = 0.01,
  gammaStart = 0.05,
  p = 1,
  sinkhornTol = 1e-12,
  gradDescTol = 1e-12,
  fastSinkhorn = TRUE,
  pushforwardStart = FALSE,
  suppressOutput = FALSE,
  WThreshold = 0
)
}
\arguments{
\item{Y}{numeric vector of observations}

\item{A}{numeric vector of domain values where you expect most of the Y values to lie in}

\item{AV}{numeric vector of domain values which you allow the functions in the space you minimize over to take}

\item{P_D}{Jacobian of mu -> W_2(mu*D, pi_hat)}

\item{muStart}{starting values for minimization}

\item{maxIter}{maximum iteration number for gradient descent algorithm}

\item{minIter}{minimum iteration number for gradient descent algorithm}

\item{sinkhornIter}{maximum Sinkhorn iterations}

\item{eps}{entropic regularization constant}

\item{gammaStart}{starting gamma value for gradient descent algorithm. Only used in first descent step.}

\item{p}{exponent of L_p norm}

\item{sinkhornTol}{tolerance for stopping criterion in Sinkhorn algorithm}

\item{gradDescTol}{tolerance for stopping criterion in gradient descent algorithm based on euclidian distance to last
vector}

\item{fastSinkhorn}{logical, controls whether to use the fast Sinkhorn algorithm}

\item{pushforwardStart}{if TRUE, starts with nearest neighbour distribution to pi_hat instead of rep(1/n)}

\item{suppressOutput}{suppress output messages?}

\item{WThreshold}{tolerance for stopping criterion for gradient descent algorithm based on the Wasserstein distance}
}
\description{
Minimize the entropic Wasserstein distance
}
\examples{
library(tidyverse)
n <- 1000
x <- seq(0, 1, length.out = n)
m <- function(x) (2*(x- 0.5))^3
Y_no_error <-  m(x)
varepsilon <- rbernoulli_custom(n, a= -0.3, b= 0.3, p=0.5)
Y <- (Y_no_error + varepsilon) \%>\% sample(n)
dat <- tibble(x=x, Y=Y, Y_no_error = Y_no_error)
N <- round(sqrt(n))
A <- seq(-1.3, 1.3, length.out = N)
stepsize <- (A[2]-A[1]) / 2
A_V <-  A[which(-1 - stepsize <= A & A <= 1 + stepsize)]
p_ber <- function(x) pbernoulli_custom(x, a = -0.3, b = 0.3, p=0.5)
P <- matrix(rep(0, times = (N) * length(A_V)), nrow = N)
P[1, ] <- p_ber(A[2] - stepsize - A_V)
for (i in 2:(N-1)) {
    P[i,] <- p_ber(A[i + 1] - stepsize - A_V) - p_ber(A[i] - stepsize - A_V)
}
P[N, ] <- 1 - p_ber(A[N] - stepsize - A_V)

l <-
   minimize_entropic_W(Y = Y,
                       A = A,
                       AV = A_V,
                       P_D = P,
                       suppressOutput = FALSE)
mu_hat <- list()
mu_hat[["vals"]] <- l$vals
mu_hat[["probs"]] <- l$probs
g_hat <- measure_to_smooth_iso(mu_hat, n)
dat <- bind_cols(dat, g_hat = g_hat)
ggplot(dat, aes(x=x, y=Y_no_error)) +
  geom_line(col="red") +
  scale_y_continuous("") +
  geom_line(aes(y=g_hat), col="blue")

}
